{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3_090522.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqHZnXxg2NUDdMfblxIQj/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darshan16011989/Ce807_Text_Analytics/blob/main/Lab3_090522.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jBNmBe9HE5q6"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Datatset import\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "metadata": {
        "id": "3ErqwZ-NI_-w"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the names of the categories\n",
        "twenty_train.target_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8sWfnuwJThv",
        "outputId": "e8589730-e7fe-43c7-fc32-57ff50560c64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how your data looks like\n",
        "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:5]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvFZwE5RJTen",
        "outputId": "ce85e18c-aff0-457e-8869-c089d2d5e1bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n",
            "Organization: University of Maryland, College Park\n",
            "Lines: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's start getting some features\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLqdpSr4JTbn",
        "outputId": "80061c0f-f661-4d9b-84c4-c522ee609c9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# here we use tf-idf features\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PC53WCREJTY3",
        "outputId": "66832d49-4dd9-4b0d-e7e2-f5622c4fa7b2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now doing what is popularly called machine learning\n",
        "# Training a Naive Bayes classifier\n",
        "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
      ],
      "metadata": {
        "id": "ULXE6zQpK_wt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
        "# The names ‘vect’ , ‘tfidf’ and ‘clf’ are arbitrary but will be used later.\n",
        "# We will be using the 'text_clf' going forward.\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "id": "lu353lcLK_t1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance of NB Classifier\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE4o3YVsK_qt",
        "outputId": "9a307a43-f0ba-49bd-cfd1-d200cb968e3c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7738980350504514"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Support Vector Machines - SVM and calculating its performance\n",
        "\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
        "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, max_iter=5, random_state=42))])\n",
        "\n",
        "text_clf_svm = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
        "predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
        "np.mean(predicted_svm == twenty_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juZQ-_HbM2W7",
        "outputId": "57b8c070-1e67-41d1-d517-b874f1139838"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8248805098247477"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid Search\n",
        "# Here, we are creating a list of parameters for which we would like to do performance tuning.\n",
        "# All the parameters name start with the classifier name (remember the arbitrary name we gave).\n",
        "# E.g. vect__ngram_range; here we are telling to use unigram and bigrams and choose the one which is optimal.\n",
        "\n",
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}"
      ],
      "metadata": {
        "id": "vXYy6V3OM2TU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we create an instance of the grid search by passing the classifier, parameters\n",
        "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
        "\n",
        "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnxpjkV_M2Qd",
        "outputId": "993e47bc-91e3-4460-b33b-c2888f607daf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To see the best mean score and the params, run the following code\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAFEYRUqM2Nb",
        "outputId": "93f7b532-5c07-4487-da21-5585f7b47cca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output for above should be: The accuracy has now increased to ~90.6% for the NB classifier (not so naive anymore! 😄)\n",
        "# and the corresponding parameters are {‘clf__alpha’: 0.01, ‘tfidf__use_idf’: True, ‘vect__ngram_range’: (1, 2)}.\n",
        "\n",
        "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
        "\n",
        "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
        "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubCVEXcqM2Ky",
        "outputId": "fff57406-48ac-4c95-baac-e72ff95ac6b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To see the best mean score and the params, run the following code\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEoT7ylhM2IT",
        "outputId": "a34a434f-8ac1-42dc-9ae2-0c2d2e2b8804"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output for above should be: The accuracy has now increased to ~90.6% for the NB classifier (not so naive anymore! 😄)\n",
        "# and the corresponding parameters are {‘clf__alpha’: 0.01, ‘tfidf__use_idf’: True, ‘vect__ngram_range’: (1, 2)}.\n",
        "\n",
        "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
        "\n",
        "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
        "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2tCjLLrM2FT",
        "outputId": "ac8bc7b4-87dd-4906-a63d-894216a26de1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:705: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs_clf_svm.best_score_\n",
        "gs_clf_svm.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joStBTpcM2CT",
        "outputId": "257d58fe-6ec8-4539-ec51-b860f7b87682"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK\n",
        "# Removing stop words\n",
        "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])"
      ],
      "metadata": {
        "id": "htoVa7TFWkX1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform gridsearch for abovbe code"
      ],
      "metadata": {
        "id": "XL-5zRpka8OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qm3J39McWsb0",
        "outputId": "89143931-9038-42bd-8bd7-b5b67a3991c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)"
      ],
      "metadata": {
        "id": "xjYUJbOcWkVF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StemmedCountVectorizer(CountVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
        "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])"
      ],
      "metadata": {
        "id": "z_J6YabAWkSd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')"
      ],
      "metadata": {
        "id": "F24dVa-iWkP1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()),\n",
        "                             ('mnb', MultinomialNB(fit_prior=False))])"
      ],
      "metadata": {
        "id": "3FSF_lrCXCaF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_mnb_stemmed = text_mnb_stemmed.fit(twenty_train.data, twenty_train.target)"
      ],
      "metadata": {
        "id": "tByGocLwXCXF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_mnb_stemmed = text_mnb_stemmed.predict(twenty_test.data)"
      ],
      "metadata": {
        "id": "rKEb_EWgXCUG"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(predicted_mnb_stemmed == twenty_test.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tQA_HpHXCRN",
        "outputId": "6d2b48a3-6ccb-4f0d-f1ed-d93c3b41d992"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8167817312798725"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(twenty_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjnLZ_TEXCOO",
        "outputId": "9e9028b3-58dc-486c-e095-53919a0308d9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W3HTKsiVXpB4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cg2e1_IFYB_g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}